{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Deep Semantic Structured Model (DSSM)\n",
    "\n",
    "\n",
    "This is a tutorial on *Deep Semantic Similarity Model* ([Huang et al. 2013]) model with MatchZoo. We use WikiQA as the example benchmark data set to show the usage.\n",
    "\n",
    "## Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block illustrates the main workflow of how to train a DSSM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchzoo import preprocessor\n",
    "from matchzoo import generators\n",
    "from matchzoo import models\n",
    "\n",
    "train, test = ... # prepare your training data and test data.\n",
    "\n",
    "dssm_preprocessor = preprocessor.DSSMPreprocessor()\n",
    "processed_tr = dssm_preprocessor.fit_transform(train, stage='train')\n",
    "processed_te = dssm_preprocessor.fit_transform(test, stage='test')\n",
    "# DSSM expect dimensionality of letter-trigrams as input shape.\n",
    "# The fitted parameters has been stored in `context` during preprocessing on training data.\n",
    "input_shapes = processed_tr.context['input_shapes']\n",
    "\n",
    "generator_tr = generators.PointGenerator(processed_tr)\n",
    "generator_te = generators.PointGenerator(processed_te)\n",
    "# Example, train with generator, test with the first batch.\n",
    "X_te, y_te = generator_te[0]\n",
    "\n",
    "dssm_model = models.DSSMModel()\n",
    "dssm_model.params['input_shapes'] = input_shapes\n",
    "dssm_model.guess_and_fill_missing_params()\n",
    "dssm_model.build()\n",
    "dssm_model.compile()\n",
    "dssm_model.fit_generator(generator_tr)\n",
    "# Make predictions\n",
    "predictions = dssm_model.predict([X_te.text_left, X_te.text_right])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Input\n",
    "\n",
    "MatchZoo expect a list of *Quintuple* as training input for DSSM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('qid0', 'did0', 'query 0', 'document 0', 'label 0'),\n",
    "         ('qid0', 'did1', 'query 0', 'document 1', 'label 1'),\n",
    "          ...,\n",
    "         ('qid1', 'did2', 'query 1', 'document 2', 'label 3')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponded columns are `(text_left_id, text_right_id, text_left, text_right, label)`. For Information Retrieval task, *text_left* is *query*, and *text_right* is document.\n",
    "\n",
    "For the test case, MatchZoo expect a list of *Quadruple* (we do not have labels) as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [('qid9', 'did5', 'query 9', 'document 5'),\n",
    "         ...,\n",
    "        ('qid2', 'did7', 'query 2', 'document 7')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take WikiQA as the example benchmark dataset to show the usage of MatchZoo. Firstly you need to downlowd the data and uncompress the data into 'MatchZoo/data/WikiQA/'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download WikiQA data...  mkdir -p ../../data/WikiQA/\n",
      "cd ../../data/WikiQA/\n",
      "wget https://download.microsoft.com/download/E/5/F/E5FCFCEE-7005-4814-853D-DAA7C66507E0/WikiQACorpus.zip\n",
      "unzip WikiQACorpus.zip\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cmd = 'mkdir -p ../../data/WikiQA/\\n' \\\n",
    "      +'cd ../../data/WikiQA/\\n' \\\n",
    "      +'wget https://download.microsoft.com/download/E/5/F/E5FCFCEE-7005-4814-853D-DAA7C66507E0/WikiQACorpus.zip\\n' \\\n",
    "      +'unzip WikiQACorpus.zip\\n'\n",
    "print ('download WikiQA data... ', cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train/dev/test files of WikiQA are WikiQA-train.tsv/WikiQA-dev.tsv/WikiQA-test.tsv under the uncompressed folder WikiQACorpus. The data format of WikiQA is as follows:\n",
    "\n",
    "`QuestionID\\tQuestion\\tDocumentID\\tDocumentTitle\\tSentenceID\\tSentence\\tLabel`\n",
    "\n",
    "We can transfer this format to the input format of MatchZoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 20360 [('Q1', 'D1-0', 'how are glacier caves formed?', 'A partly submerged glacier cave on Perito Moreno Glacier .', '0\\n'), ('Q1', 'D1-1', 'how are glacier caves formed?', 'The ice facade is approximately 60 m high', '0\\n'), ('Q1', 'D1-2', 'how are glacier caves formed?', 'Ice formations in the Titlis glacier cave', '0\\n'), ('Q1', 'D1-3', 'how are glacier caves formed?', 'A glacier cave is a cave formed within the ice of a glacier .', '1\\n'), ('Q1', 'D1-4', 'how are glacier caves formed?', 'Glacier caves are often called ice caves , but this term is properly used to describe bedrock caves that contain year-round ice.', '0\\n'), ('Q2', 'D2-0', 'How are the directions of the velocity and force vectors related in a circular motion', 'In physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path.', '0\\n'), ('Q2', 'D2-1', 'How are the directions of the velocity and force vectors related in a circular motion', 'It can be uniform, with constant angular rate of rotation (and constant speed), or non-uniform with a changing rate of rotation.', '0\\n'), ('Q2', 'D2-2', 'How are the directions of the velocity and force vectors related in a circular motion', 'The rotation around a fixed axis of a three-dimensional body involves circular motion of its parts.', '0\\n'), ('Q2', 'D2-3', 'How are the directions of the velocity and force vectors related in a circular motion', 'The equations of motion describe the movement of the center of mass of a body.', '0\\n'), ('Q2', 'D2-4', 'How are the directions of the velocity and force vectors related in a circular motion', 'Examples of circular motion include: an artificial satellite orbiting the Earth at constant height, a stone which is tied to a rope and is being swung in circles, a car turning through a curve in a race track , an electron moving perpendicular to a uniform magnetic field , and a gear turning inside a mechanism.', '0\\n')]\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../../data/WikiQA/WikiQACorpus/'\n",
    "\n",
    "def read_data(input):\n",
    "    output_list = []\n",
    "    index = 0\n",
    "    with open(input) as fin:\n",
    "        for l in fin:\n",
    "            tok = l.split('\\t')\n",
    "            if index != 0:\n",
    "                output_list.append((tok[0], tok[4], tok[1], tok[5], tok[6])) # qid, did, q, d, label \n",
    "            index += 1\n",
    "    return output_list\n",
    "\n",
    "train = read_data(data_folder + 'WikiQA-train.tsv')\n",
    "print ('train', len(train), train[0:10])\n",
    "dev = read_data(data_folder + 'WikiQA-dev.tsv')\n",
    "test = read_data(data_folder + 'WikiQA-test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "You can pre-process your DSSM input in three lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2018-08-18 15:44:26,946 - matchzoo.preprocessor.dssm_preprocessor - INFO - Start building vocabulary & fitting parameters.\n",
      "100%|██████████| 20360/20360 [26:09<00:00, 12.98it/s]\n",
      "2018-08-18 16:10:36,295 - matchzoo.preprocessor.dssm_preprocessor - INFO - Start processing input data for train stage.\n",
      "100%|██████████| 20360/20360 [25:19<00:00, 13.40it/s]\n",
      "2018-08-18 16:35:55,860 - matchzoo.preprocessor.dssm_preprocessor - INFO - Start processing input data for test stage.\n",
      "100%|██████████| 6165/6165 [07:52<00:00, 13.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dssm preprocessor.\n",
    "from matchzoo import preprocessor\n",
    "dssm_preprocessor = preprocessor.DSSMPreprocessor()\n",
    "processed_tr = dssm_preprocessor.fit_transform(train, stage='train')\n",
    "processed_te = dssm_preprocessor.fit_transform(test, stage='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be interested that what is *processed_tr*? Actually, *processed_tr* is a **MatchZoo DataPack** (see matchzoo/datapack.py) data structure. It contains a *pandas DataFrame* to host all the pre-processed records, and a `context` property (dictionary) consists of all the parameters fitted during pre-processing. The `fit_transform` method is a linear combination of two methods:\n",
    "\n",
    "1. Fit parameters using the `fit` function, this only happens when `stage='train'`.\n",
    "2. Transform data into expected format.\n",
    "\n",
    "So the previous three lines code can also be written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dssm preprocessor.\n",
    "from matchzoo import preprocessor\n",
    "dssm_preprocessor = preprocessor.DSSMPreprocessor()\n",
    "processed_tr = dssm_preprocessor.fit_transform(train, stage='train')\n",
    "# We do not need to fit any parameters during the testing stage.\n",
    "# So we can call transform directly.\n",
    "processed_te = dssm_preprocessor.transform(test, stage='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described, the fitted parameters were stored in **context** property, to access the context, just call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  9608\n"
     ]
    }
   ],
   "source": [
    "print('vocab size: ', len(processed_tr.context['term_index']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What has been stored in the context? We stored `input_shapes` in the context property. Since DSSM model's model input shape is dynamic (it depends on user's training data to generate tri-letters), so you **must** manually set models input shape, we'll discuss it in the model training section.\n",
    "\n",
    "What is `dssm_preprocessor` actually doing? The `dssm_preprocessor` is calling a sequence of `process_units`. Each `process_unit` is designed to perform one atom operation on input data. For instance, in `dssm_preprocessor`, we called:\n",
    "\n",
    "1. TokenizeUnit: Perform tokenization on raw input data.\n",
    "2. LowercaseUnit: Transform all tokens into lower case.\n",
    "3. PuncRemovalUnit: Remove all the punctuations.\n",
    "4. StopRemovalUnit: Remove all the stopwords.\n",
    "5. NgramLetterUnit: Create n-gram-letters (by default we're creating tri-letters) as input data, for example: the token `test` we be transformed to `['#te', 'tes', 'est', 'st#']`.\n",
    "6. VocabularyUnit: Create vocabulary to get the dimensionality of `tri-letters`.\n",
    "7. WordHashingUnit: Create **WordHashing** layer as described in the paper.\n",
    "\n",
    "## Data Generation\n",
    "\n",
    "For memory efficiency, we expect you to use **generator** to generate batches of data on the fly. For example, we can create a **PointGenerator** as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchzoo import generators\n",
    "generator_tr = generators.PointGenerator(processed_tr, batch_size=100)\n",
    "generator_te = generators.PointGenerator(processed_te, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the first batch of trainig data, just call `X_train, y_train = generator[0]`.\n",
    "\n",
    "## Train Your DSSM Model\n",
    "\n",
    "To train a DSSM model, we need to create an instance of DSSMModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchzoo import models\n",
    "dssm_model = models.DSSMModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to set hyper-parameters to our DSSM Model. In general, there are two types of parameters:\n",
    "\n",
    "**Required parameters**: For DSSM, since the `input_shapes` depend on the dimensionality of fitted training data, you're required to set this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fitted parameters is stored in the `context` property of pre-processor instance.\n",
    "input_shapes = processed_tr.context['input_shapes']\n",
    "dssm_model.params['input_shapes'] = input_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tunable parameters**: For DSSM, you're allowed to tune these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'w_initializer': 'glorot_normal', # Weight initializer, see keras documentation.\n",
    "            'b_initializer': 'zeros', # Bias initializer, see keras documentation.\n",
    "            'dim_fan_out': 128, # Dimension of output layer.\n",
    "            'dim_hidden': 300, # Dimension of hidden layer.\n",
    "            'activation_hidden': 'tanh', # Activation function of hidden layer, see keras documentation.\n",
    "            'num_hidden_layers': 2, # Number of hidden layers.\n",
    "            'optimizer': 'sgd', # By default, we're using sgd, see keras documentation.\n",
    "            'task': matchzoo.tasks.Classification, # Default Classification, you can use matchzoo.engine.Ranking\n",
    "            'loss': 'categorical_crossentropy', # categorical_crossentropy by default, see keras documentation.\n",
    "            'metric': 'acc', # Accuracy by default, see keras documentation.\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as **required parameters**, use `dssm_model.params['parameter-name'] = parameter-value` to set the hyper parameters. If you want to keep everything by default values, just use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dssm parameters:  name                          DSSMModel\n",
      "model_class                   <class 'matchzoo.models.dssm_model.DSSMModel'>\n",
      "input_shapes                  [(9609,), (9609,)]\n",
      "task                          <matchzoo.tasks.classification.Classification object at 0x7fc63ea8f9b0>\n",
      "metrics                       ['acc']\n",
      "loss                          categorical_crossentropy\n",
      "optimizer                     sgd\n",
      "w_initializer                 glorot_normal\n",
      "b_initializer                 zeros\n",
      "dim_fan_out                   128\n",
      "dim_hidden                    300\n",
      "activation_hidden             tanh\n",
      "num_hidden_layers             2\n"
     ]
    }
   ],
   "source": [
    "dssm_model.guess_and_fill_missing_params()\n",
    "print('dssm parameters: ', dssm_model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model after all the parameters were settled, call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.4785 - acc: 0.8561\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 0.2728 - acc: 0.9511\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 0.2430 - acc: 0.9448\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 4s 19ms/step - loss: 0.2131 - acc: 0.9517\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 4s 19ms/step - loss: 0.2126 - acc: 0.9484\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.2156 - acc: 0.9453\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 4s 19ms/step - loss: 0.2018 - acc: 0.9498\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 0.2090 - acc: 0.9464\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 0.1969 - acc: 0.9503\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 0.1947 - acc: 0.9500\n"
     ]
    }
   ],
   "source": [
    "dssm_model.build()\n",
    "dssm_model.compile()\n",
    "# Fit the dssm model on generator.\n",
    "dssm_model.fit_generator(generator_tr, steps_per_epoch=200, epochs=10)\n",
    "# Make predictions on the first batch of test data\n",
    "X_te, y_te = generator_te[0]\n",
    "predictions = dssm_model.predict([X_te.text_left, X_te.text_right])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also persist your trained model using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchzoo import engine\n",
    "# Save the model to desktop.\n",
    "dssm_model.save('/your-path-to-desktop/Desktop/')\n",
    "# And load the model from desktop.\n",
    "engine.load_model('/your-path-to-desktop/Desktop/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[Huang et al. 2013] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In Proc. CIKM. ACM, 2333–2338."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
